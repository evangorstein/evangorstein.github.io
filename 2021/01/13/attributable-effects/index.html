<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=4321&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.126.1">


<title>Randomization Inference Part 2: Attributable Effects - Evan Gorstein</title>
<meta property="og:title" content="Randomization Inference Part 2: Attributable Effects - Evan Gorstein">


  <link href='//localhost:4321/favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/uwlogo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/">Blog</a></li>
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/evangorstein">GitHub</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">9 min read</span>
    

    <h1 class="article-title">Randomization Inference Part 2: Attributable Effects</h1>

    
    <span class="article-date">2021-01-13</span>
    

    <div class="article-content">
      


<font size="2">
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In the last post, I presented a framework for performing causal inference in a matched-pair randomized experiment. The Wilcoxon signed rank statistic was introduced, and we saw how it could be used to obtain point and interval estimates of a constant additive effect. This approach will not work when the true effect of treatment differs across individuals, and so in this post, I want to discuss a method for quantifying non-constant causal effects. The quantity that we will define for this task is known as the “attributable effect” of treatment. This discussion is adapted from Chapter 2 of Paul Rosenbaum’s <em>Design of Observational Studies</em> (2010).</p>
</div>
<div id="exceptional-pairs" class="section level1">
<h1>Exceptional Pairs</h1>
<p>We adopt the same experimental set-up as in the previous post with <span class="math inline">\(I\)</span> pairs matched for pre-treatment covariates and treatment assignment randomized within each pair. Let’s consider for the moment a subset <span class="math inline">\(\mathscr{I} \subseteq \{1,2,3,...I\}\)</span> of <span class="math inline">\(m\)</span> of these <span class="math inline">\(I\)</span> pairs. In order to allow the heterogeneity of the effect to play a role in our calculations, let’s try to identify the pair <span class="math inline">\(i_\mathscr{I}\)</span> in <span class="math inline">\(\mathscr{I}\)</span> whose two individuals exhibit the largest difference in outcomes. Surely, this is a noteworthy pair, one that might provide evidence about the direction of the effect of treatment. For example, we might consider it evidence for a positive treatment effect if within this exceptional pair, the treated unit’s observed response is the larger of the two. Let <span class="math inline">\(H_\mathscr{I}\)</span> be an indicator for just this. In other words, <span class="math inline">\(H_\mathscr{I} = 1\)</span> if in the pair in <span class="math inline">\(\mathscr{I}\)</span> with the largest disparity in observed responses, the treated-minus-control difference is positive and <span class="math inline">\(H_\mathscr{I} = 0\)</span> otherwise. Of course, we may have just gotten lucky in the sense that even without a positive effect, we still might find that the treated unit in <span class="math inline">\(i_\mathscr{I}\)</span> has the larger observed response. Indeed, we saw in the previous post that under the sharp null hypothesis of no treatment effect in any unit, we have <span class="math display">\[Y_{i} := (Z_{i1}-Z_{i2})(R_{i1}-R_{i2})=(Z_{i1}-Z_{i2})(r_{Ci1}-r_{Ci2}) \tag{1}\]</span>for all <span class="math inline">\(i\)</span>, where <span class="math inline">\(r_{Cij}\)</span> is the potential outcome under control of unit <span class="math inline">\(j\)</span> in pair <span class="math inline">\(i\)</span>. Since these potential outcomes are fixed constants, we can see that a flip of the randomization coin determines the sign of the treated-minus-control difference <span class="math inline">\(Y_{i}\)</span> for all <span class="math inline">\(i\)</span> and, in particular, for that most exceptional <span class="math inline">\(Y_{i_\mathscr{I}}\)</span>, under the sharp null hypothesis. Thus, when there is no effect for anyone, we will still have a 50-50 shot that <span class="math inline">\(H_\mathscr{I}=1\)</span>.</p>
<p>In order to account for luck, we now define a different indicator <span class="math inline">\(H_{C\mathscr{I}}\)</span>. This indicator ranks the pairs in <span class="math inline">\(\mathscr{I}\)</span> according to their differences in <em>potential outcomes under control</em>, <span class="math inline">\(|r_{Ci1}-r_{Ci2}|\)</span>, instead of the difference in observed responses <span class="math inline">\(|R_{i1}-R_{i2}|\)</span>. It equals 1 if in the pair with the largest such difference, the treated unit is the one with the larger potential outcome under control. This is a weird thing to consider, but if the sharp null hypothesis of no effect in any unit is true, then <span class="math inline">\(|r_{Ci1}-r_{Ci2}| = |R_{i1}-R_{i2}|\)</span> for all <span class="math inline">\(i\)</span>, so <span class="math inline">\(H_{C\mathscr{I}} = H_{\mathscr{I}}\)</span>. So one might imagine that deviation of <span class="math inline">\(H_{\mathscr{I}}\)</span> from <span class="math inline">\(H_{C\mathscr{I}}\)</span> measures deviation from the sharp null hypothesis.</p>
</div>
<div id="attributable-effect" class="section level1">
<h1>Attributable Effect</h1>
<p>Let’s now recall that <span class="math inline">\(\mathscr{I}\)</span> was just one arbitrary subset of pairs, so we actually want to go through this for every single subset of pairs of size <span class="math inline">\(m\)</span> and sum the results. Let <span class="math inline">\(\mathscr{K}\)</span> be the collection of all subsets of <span class="math inline">\(m\)</span> distinct pairs. We define the statistic <span class="math inline">\(\tilde{T}\)</span> to be the tally of all the “successes” as we loop through these subsets, i.e. <span class="math inline">\(\tilde{T}= \sum_{\mathscr{I}\in\mathscr{K}}{H_\mathscr{I}}\)</span>. Similarly, the count of “successes” if we went according to the potential responses under control is given by <span class="math inline">\(\tilde{T_C}= \sum_{\mathscr{I}\in\mathscr{K}}{H_{C\mathscr{I}}}\)</span>, a quantity which in general is unobserved. A quantity that measures evidence for a treatment effect while accounting for luck is the difference between these two tallies, <span class="math inline">\(A=\tilde{T} - \tilde{T}_{C} = \sum_{\mathscr{I}\in\mathscr{K}}{H_\mathscr{I} - H_{C\mathscr{I}}}\)</span>. In general, <span class="math inline">\(A\)</span> is an integer between <span class="math inline">\(-|\mathscr{K}|\)</span> and <span class="math inline">\(|\mathscr{K}|\)</span> representing the change in the number of successes which can be attributed to treatment, i.e. the “attributable effect”. It is common and more informative to discuss attributable effects in terms of proportions, i.e. <span class="math inline">\(A/|\mathscr{K}|\)</span>.</p>
</div>
<div id="calculations" class="section level1">
<h1>Calculations</h1>
<p>Now that we know what we’re interested in, let’s see if we can calculate it. There seem to be a couple of significant obstacles to calculating <span class="math inline">\(A\)</span>:
1. We do not observe <span class="math inline">\(\tilde{T}_C\)</span>.
2. Although we observe <span class="math inline">\(\tilde{T}\)</span>, it seems pretty awful to calculate, involving the separate consideration of every subset of pairs of size <span class="math inline">\(m\)</span>.</p>
<p>Upon further reflection, however, both of these obstacles can be overcome. First, although we don’t know the exact value of <span class="math inline">\(\tilde{T}_C\)</span>, we know its distribution; second, <span class="math inline">\(\tilde{T}\)</span> ends up being easy to calculate.</p>
<p>Starting with the latter, <span class="math inline">\(\tilde{T}\)</span> can actually be expressed in the form of a signed rank statistic very similar to Wilcoxon’s, allowing us to calculate it with ease. In particular, we have <span class="math inline">\(T=\sum_{i=1}^I{\mathop{\mathrm{sgn}}(Y_i)\tilde{q_i}}\)</span>, where <span class="math inline">\(\tilde{q_i}\)</span> is a quantity that we will now define. Recall that <span class="math inline">\(q_i\)</span>, without the tilde, is just the rank of <span class="math inline">\(|Y_i|\)</span>, defined for the calculation of Wilcoxon’s statistic. Now for a fixed pair <span class="math inline">\(i\)</span>, if <span class="math inline">\(q_i &lt; m\)</span>, then in any subset of <span class="math inline">\(m\)</span> pairs, there will be at least one pair “more exceptional” than pair <span class="math inline">\(i\)</span>, and so pair <span class="math inline">\(i\)</span> contributes nothing to our tally of “successes”. On the other hand, if <span class="math inline">\(m \le q_i\)</span>, then the number of subsets of size <span class="math inline">\(m\)</span> in which <span class="math inline">\(i\)</span> appears as most exceptional is just the number of ways to choose <span class="math inline">\(m-1\)</span> pairs from the <span class="math inline">\(q_{i}-1\)</span> pairs less exceptional that pair <span class="math inline">\(i\)</span>. This analysis motivates our definition of <span class="math inline">\(\tilde{q_i}\)</span>as</p>
<p><span class="math display">\[\tilde{q_i} = {q_i-1 \choose m-1} \text{ for } q_i \ge m \text{, } \tilde{q_i}=0 \text{ for }  q_i &lt; m\]</span>
With <span class="math inline">\(\tilde{q_i}\)</span> thus defined, <span class="math inline">\(\sum_{i=1}^I{\mathop{\mathrm{sgn}}(Y_i)\tilde{q_i}}\)</span> describes an alternative approach to tallying “successes,” looping through pairs instead of looping through subsets of pairs. The result, of course, will be the same, although written in this form, it’s much easier to calculate. Notice also that if <span class="math inline">\(m=2\)</span>, <span class="math inline">\(\tilde{q_i} = q_i-1\)</span>, so we recover the Wilcoxon statistic with ranks starting at <span class="math inline">\(0\)</span> and going to <span class="math inline">\(I-1\)</span> instead of starting at <span class="math inline">\(1\)</span> and going to <span class="math inline">\(I\)</span>.</p>
<p>What about the distribution of <span class="math inline">\(\tilde{T}_C\)</span>? Well, <span class="math inline">\(\tilde{T}_C\)</span> can also be written as the sum of the signed ranks of each of the treated-minus-control differences, where we now use the potential responses under control for each unit to calculate these differences. As we saw in Equation 1, when we use potential responses, the sign of each pair’s treated-minus-control difference is determined by a fair coin flip, so <span class="math inline">\(\tilde{T}_C\)</span> is just the sum of <span class="math inline">\(I\)</span>independent random variables, each equal to <span class="math inline">\(\tilde{q_i}\)</span> or <span class="math inline">\(0\)</span> with equal probability <span class="math inline">\(\frac{1}{2}\)</span>. Consequently, if we assume that there are no ties among the treated-minus-control differences, then we know its distribution before we even observe our data. In particular, its expected value and variance are given by</p>
<p><span class="math display">\[\mathrm{E}(\tilde{T}_C)=\frac{1}{2}\sum_{i=1}^I{\tilde{q_i}}=\frac{1}{2}|\mathscr{K}|\]</span><br />
and <span class="math display">\[\mathrm{Var}(\tilde{T}_C)=\frac{1}{4}\sum_{i=1}^I{\tilde{q_i}^2}=\frac{1}{4}\sum_{i=m}^I{ {i-1 \choose m-1}^2 }\]</span></p>
<p>A point estimate for the attributable effect is thus <span class="math display">\[\hat{A}=\tilde{T}-\mathrm{E}(\tilde{T}_C)=\tilde{T} - \frac{1}{2}|\mathscr{K}|\]</span>or in proportional terms, <span class="math display">\[\frac{\tilde{T} - |\mathscr{K}|/2} {|\mathscr{K}|}= \frac{\tilde{T}}{|\mathscr{K}|} - .5\]</span></p>
</div>
<div id="confidence-intervals" class="section level1">
<h1>Confidence Intervals</h1>
<p>The Lyapunov version of the central limit theorem tells us that the assymptotic distribution of the sum of independent, not necessarilly identical random variables follows a normal distribution. <span class="math inline">\(\tilde{T}_C\)</span> is a finite sum of independent random variables, but for large enough <span class="math inline">\(I\)</span>, the assymptotic distribution provides a solid approximation. Using this approximation, we can calculate the smallest value <span class="math inline">\(t_\alpha\)</span> such that <span class="math inline">\(P(\tilde{T}_C\leq t_\alpha) \geq 1 - \alpha\)</span> with</p>
<p><span class="math display">\[t_\alpha = \mathrm{E}(\tilde{T}_C) + \Phi^{-1}(1-\alpha)\sqrt{\mathrm{Var}(\tilde{T}_C)} \]</span></p>
<p>where <span class="math inline">\(\Phi^{-1}\)</span> is the quantile function for the standard normal distribution. The confidence statement we can then make about <span class="math inline">\(A=T_\mathscr{I} - T_{C\mathscr{I}}\)</span> is <span class="math display">\[P(A \geq \tilde{T} - t_\alpha) \geq 1-\alpha \]</span>
In terms of proportions, we state with <span class="math inline">\(1-\alpha\)</span> confidence that <span class="math display">\[\frac{A}{|\mathscr{K}|} \geq \frac{\tilde{T} - t_\alpha}{|\mathscr{K}|}\]</span></p>
</div>
<div id="detecting-heterogenous-effects" class="section level1">
<h1>Detecting Heterogenous Effects</h1>
<p>Returning to our original motivation for introducing attributable effects, let’s conclude by analyzing the role that <span class="math inline">\(m\)</span>, the size of our subsets, plays in our calculations. In Part 1, we saw that the Wilxon signed rank statistic does a great job of efficiently estimating a constant treatment effect in a randomized, matched pair experiment. We also mentioned that Wilcoxon’s statistic could be used to test a null hypothesis of a particular non-constant effect, and in theory, this test could be inverted to produce a confidence set in a <span class="math inline">\(\mathbb{R}^{2I}\)</span> parameter space. However, this would not be a pretty set and therefore of little use to us. To address this gap, we introduced in this post the attributable effect, an interpretable quantity which summarizes the effect of a treatment that is not the same for all individuals.</p>
<p>Let us now update this description slightly by looking at the role of <span class="math inline">\(m\)</span>. If <span class="math inline">\(m=2\)</span>, then the attributable effect is obtained from making comparisons between just two pairs at a time. What kind of effect will this do a good job of detecting and which kind of effect will it discount? I claim that a constant tretment effect, even one which is modest in size, should be detected using this method, whereas a heterogenous effect, which is large for a small number of individuals, but <span class="math inline">\(0\)</span> for the majority, will probably be underestimated. This is because most of the comparisons will not include any of the small number of highly affected individuals, and in those which do, there is no extra credit given for the size of the effect–the tally of successes goes up by at most one no matter what. This result is also reflected by the observation we made earlier in our calculations: When <span class="math inline">\(m=2\)</span>, <span class="math inline">\(\tilde{T}\)</span> is virtually identical to the Wilcoxon statistic, which only does a good job of detecting homogenous effects.</p>
<p>By increasing <span class="math inline">\(m\)</span>, we consider larger collections of pairs one at a time. By virtue of their size, these collections are more likely to include one of the highly affected individuals and, as a result, our tally of successes will more appropriately account for the treatment effect. In other words, the measure of attributable effects as we defined it is more sensitive to large but uncommon effects the larger <span class="math inline">\(m\)</span> is.</p>
<p>In Rosenbaum’s textbook, he illustrates this using a study of the impact of a employment and training program on the earnings of economically disadvantaged workers upon leaving the program. He computes the estimate of the attributable effect with <span class="math inline">\(m\)</span>=2 as 10.8% with a 95% confidence level for an effect of at least 3.8%. He also computes estimates for <span class="math inline">\(m=20\)</span>: a point estimate of a 35.7% increase in successes and a 95% confidence interval of at least a 15.8% increase. The conclusion he draws from these diverging estimates is that the training program had a a large but uncommon effect, dramatically increasing the earnings of a few select workers, but leaving the majority of wages unchanged.</p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  


  </body>
</html>

