<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.0" />


<title>Pivoting a cdf - Evan Gorstein</title>
<meta property="og:title" content="Pivoting a cdf - Evan Gorstein">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/uwlogo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/">Blog</a></li>
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/evangorstein">GitHub</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">Pivoting a cdf</h1>

    
    <span class="article-date">2021-08-12</span>
    

    <div class="article-content">
      
<script src="/2021/08/12/pivoting-a-cdf/index_files/header-attrs/header-attrs.js"></script>


<p><font size="1"></p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The title of this post refers to a technique for constructing confidence sets for real-valued parameters that is extremely general. The generality of the techinque came as quite the surprise to me when I first learned about it this past year in my first year Math Stat class. My surprise was that a single method could be employed to construct confidence sets in every setting (i.e. every parameterized family of distributions in which a real-valued parameter is to be targeted with a confidence set)! Who knew?!</p>
<p>These were my thoughts upon first learning the theory behind the method. However, after seeing a few use-cases, I discovered that my initial amazement was näive. Alas, pivoting a cdf is not some magic bullet of parametric set estimation. For any given problem, there are two dimensions in which the method may be limited: ease of implementation and performance of the result. To begin with the first, just because we <em>can</em> pivot a cdf, does not mean we will necessarilly <em>want</em> to. In particular, there’s a good chance we’ll have to rely on inexact computations to perform the pivot. Second, even if the method can be executed to arrive at some confidence set of a desired level, perhaps relying on a computational approximation in the process, there is no guarantee that this confidence set will be a particularly good one! We will see that the performance of the resulting confidence set depends on the statistic that we start with.</p>
<p>To draw a connection to my previous posts, I am here discussing parametric inference from a random sample. In this setting, we assume a specific functional form for the distribution of our data and we proceed to make inferences (perform hypothesis tests and develop estimates) about an unknown parameter in this function. In contrast, in my first two blog posts, I discuss methods of inference which rely only on an assumption of randomization, an example of non-parametric statistics.</p>
<p>Without further adieu, here’s the method:</p>
<div id="pivoting-a-cdf" class="section level2">
<h2>Pivoting a CDF</h2>
<p><strong>Let <span class="math inline">\(T\)</span> be a real-valued statistic with a continuous cdf <span class="math inline">\(F_\theta(t)\)</span>, where <span class="math inline">\(\theta\in\Theta\subset\mathbb{R}\)</span>. Let <span class="math inline">\(\alpha_1 + \alpha_2 = \alpha\)</span> where <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\alpha_2\)</span> are non-negative and their sum <span class="math inline">\(\alpha\)</span> is strictly between <span class="math inline">\(0\)</span> and <span class="math inline">\(1.\)</span> If <span class="math inline">\(F_\theta(t)\)</span> is non-increasing in <span class="math inline">\(\theta\)</span> for each <span class="math inline">\(t\)</span>, define</strong></p>
<p><span class="math display">\[\begin{align}
U(t)= \sup \{\theta : F_\theta(t) \geq \alpha_1 \},       &amp;&amp;L(t)= \inf \{\theta : F_\theta(t) \leq 1-\alpha_2 \} 
\end{align}\]</span></p>
<p><strong>If <span class="math inline">\(F_\theta(t)\)</span> is non-decreasing in <span class="math inline">\(\theta\)</span> for each <span class="math inline">\(t\)</span>, define</strong></p>
<p><span class="math display">\[\begin{align}
L(t)= \inf \{\theta : F_\theta(t) \geq \alpha_1 \},       &amp;&amp;U(t)= \sup \{\theta : F_\theta(t) \leq 1-\alpha_2 \} 
\end{align}\]</span></p>
<p><strong>Then <span class="math inline">\([L(T), U(T)]\)</span> is a <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span>.</strong></p>
<p>In the case of a discrete statistic with a discontinuous CDF, the statement changes only slightly with <span class="math inline">\(\lim_{s\to t^-} F_\theta(t)\)</span> replacing <span class="math inline">\(F_\theta(t)\)</span> in the inequality <span class="math inline">\(F_\theta(t) \leq 1-\alpha_2\)</span>.</p>
</div>
<div id="whats-going-on-here-pre-proof-explanation" class="section level2">
<h2>What’s going on here? (Pre-proof explanation)</h2>
<p>The method can actually be viewed as a specific example of a more general strategy for constructing confidence interval, known as “pivoting” (since I promised that the method is as general as can be, this might not make much sense, but bear with me for now). A pivot is defined as a function of both the data and of the unknown parameters which has a distribution that does not depend on any unknown parameters. The cool thing about pivots is that they yield confidence intervals of any level through inversion! Here is some notation to go along with the idea:</p>
<p>Suppose <span class="math inline">\(q(X, \theta)\)</span> is a pivot. By definition, this means that the distribution of <span class="math inline">\(q(X, \theta)\)</span> is known to us and so in particular, for any desired <span class="math inline">\(\alpha\)</span>, we can find a set <span class="math inline">\(A\)</span> such that <span class="math inline">\(P(q(X, \theta) \in A) \geq 1-\alpha\)</span>. Then the set <span class="math inline">\(C(X)=\{\theta : q(X, \theta) \in A\}\)</span> is a level <span class="math inline">\(1-\alpha\)</span> confidence set.</p>
<p>Now while the theory is nice, let me reitterate that theory <span class="math inline">\(\neq\)</span> practice, and one can encounter all sorts of difficulties in both finding the set <span class="math inline">\(A\)</span> and inverting <span class="math inline">\(q(x, \theta) \in A\)</span> into a statement about <span class="math inline">\(\theta\)</span>. In particular, we may have to rely on computation instead of an exact solution for either step (or both), and the confidence set that we eventually obtain is by no means guaranteed to be of a simple form. In one special case, it will be: when both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(q(X, \theta)\)</span> are real-valued and <span class="math inline">\(q(X, \theta)\)</span> is monotone in <span class="math inline">\(\theta\)</span> for every fixed X, then choosing <span class="math inline">\(A\)</span> to be an interval will lead to <span class="math inline">\(C(X)\)</span> being an interval. Meanwhile, when <span class="math inline">\(\theta\)</span> is multivariate, then the process of inverting <span class="math inline">\(q(X, \theta) \in A\)</span> to obtain a confidence set in <span class="math inline">\(\mathbb{R}^n\)</span> can be quite complicated.</p>
<p>Still, what we’ve discovered is that <em>in theory</em> pivots immediately gives us confidence sets. Thus, the task of developing a good set estimator boils down to finding a good pivot. Now usually, when we are working on developing a set estimator, we have already done some thinking about our parametric setting and have identified a “sufficient statistic”. A statistic is any feature of the data, such as the sample mean, sample variance or the minimum or maximum observation. A sufficient statistic is a feature of the data which contains as much information about the parameter as the entire sample. But how does this help us? We are looking for pivot, and statistics are decidedly not pivots, since their distributions depend on the parameter! The key insight that now comes into play is that statistics can be turned into pivots by plugging them into their own cdf! The reason for this is that in general when you plug a random variable its own cdf, you get a standard uniform random variable (when the original random variable is continuous; when it’s discrete, you get something stochastically greater than a standard uniform). This deserves a proof, but the intuition is clear: (Provide intution). Signficant for our purposes is that the distribution of a standard uniform does not depend on any unknown parameter, and so we have a pivot!</p>
<p>To recap, what we’ve found is that any time we have a statistic, we have a pivot and any time we have a pivot, we get a confidence set. This is formalized in the following proof.</p>
</div>
<div id="proof-of-pivoting-cdf-for-a-continuous-random-variable" class="section level2">
<h2>Proof of pivoting cdf for a continuous random variable</h2>
<p>As discussed, we rely on the following fact: <span class="math inline">\(F_\theta(T) \sim \mathit{Uniform}(0,1)\)</span>, and we use it as a pivot. We have</p>
<p><span class="math display">\[ P(\alpha_1 \leq F_\theta(T) \leq 1-\alpha_2)= 1-\alpha_2-\alpha_1=1-\alpha,
\]</span>
and by inverting we get a confidence set with confidence coefficient <span class="math inline">\(1-\alpha\)</span>:</p>
<p><span class="math display">\[C(T)=\{\theta : \alpha_1 \leq F_\theta(T) \leq 1-\alpha_2\} 
\]</span></p>
<p>Notice that we haven’t invoked any assumptions about the monotonicity of <span class="math inline">\(F_\theta\)</span> in <span class="math inline">\(\theta\)</span> in the proof yet, so we are working in extreme generality. This is what I mean when I say that the method of pivoting a CDF is always available, requiring only a statistic with a known cdf. The confidence set <span class="math inline">\(C(T)\)</span> can always be defined, but for <span class="math inline">\(C(T)\)</span> to be of a nice form, i.e. an interval, we need <span class="math inline">\(F_\theta(t)\)</span> to be non-increasing or non-decreasing in <span class="math inline">\(\theta\)</span> for every <span class="math inline">\(t\)</span>.</p>
<p>We will prove the case where <span class="math inline">\(F_\theta(t)\)</span> is non-increasing in <span class="math inline">\(\theta\)</span>, so we define</p>
<p><span class="math display">\[\begin{align}
U(t)= \sup \{\theta : F_\theta(t) \geq \alpha_1 \},       &amp;&amp;L(t)= \inf \{\theta : F_\theta(t) \leq 1-\alpha_2 \} 
\end{align}\]</span><br />
and hope to prove <span class="math inline">\(C(T)=[L(T), U(T)]\)</span>.</p>
<p>This can be checked: For a fixed <span class="math inline">\(t\)</span>, <span class="math inline">\(F_\theta(t) \geq \alpha_1\)</span> is equivalent to <span class="math inline">\(\theta \leq U(t)\)</span> and <span class="math inline">\(F_\theta(t) \leq 1- \alpha_2\)</span> is equivalent to <span class="math inline">\(L(t) \leq \theta\)</span> by the definitions of supremum and infimum and the non-increasingness of <span class="math inline">\(F_\theta(t)\)</span> in <span class="math inline">\(\theta\)</span>.</p>
<p>Thus, <span class="math inline">\(C(T)=[L(T), U(T)]\)</span>.</p>
<p>Note that in case the equation <span class="math inline">\(F_\theta(t)=\alpha_1\)</span> or <span class="math inline">\(F_\theta(t)=1-\alpha_2\)</span> has a unique solution for <span class="math inline">\(theta\)</span>, those solutions are <span class="math inline">\(U(T)\)</span> for the first and <span class="math inline">\(L(T)\)</span> for the second.</p>
<div id="examples" class="section level3">
<h3>Examples</h3>
</div>
</div>
<div id="exponential-location-family" class="section level2">
<h2>Exponential location family</h2>
<p>Let <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> be a random sample from the pdf <span class="math inline">\(f_\theta(x)= e^{-(x-\theta)}\)</span> for <span class="math inline">\(x &gt; \theta\)</span> with <span class="math inline">\(\theta \in \mathbb{R}\)</span>. We identify the minimum observation <span class="math inline">\(X_{(1)}\)</span> as the sufficient and complete statistic–it efficiently packages all of the information about <span class="math inline">\(\theta\)</span> that can be gleaned from our sample. Coincidentally, this statistic is the maximum likelihood estimator (MLE) for <span class="math inline">\(\theta\)</span>, and it also follows an exponential distribution with the same location parameter, but with rate parameter <span class="math inline">\(n\)</span>. Its cdf is therefore <span class="math inline">\((1-\exp(-n(t-\theta)))I(t&gt;\theta)\)</span>, which is decreasing in <span class="math inline">\(\theta\)</span> for every <span class="math inline">\(t\)</span>. In this case, the equations</p>
<p><span class="math display">\[\begin{align}
\frac{\alpha}{2} &amp;= 1-e^{-n(t-\theta)} \\       
1-\frac{\alpha}{2} &amp;= 1-e^{-n(t-\theta)} 
\end{align}\]</span>
each have unique solutions for <span class="math inline">\(\theta\)</span>.
We solve the first to get</p>
<p><span class="math display">\[ U(T)= T + \frac{1}{n}\log \left( 1-\frac{\alpha}{2} \right)
\]</span>
and the second to get
<span class="math display">\[ L(T)= T + \frac{1}{n}\log \left(\frac{\alpha}{2} \right)
\]</span></p>
<p>Here is some code which plots the above confidence interval for each of 100 samples of size 100. The true value of <span class="math inline">\(\theta\)</span> in these simulations is 7, as indicated by the vertical line. The circles are plots of <span class="math inline">\(X_{(1)}-1/n\)</span>, which is the best unbiased point estimator for <span class="math inline">\(\theta\)</span>. We see that 97 of the 100 confidence intervals cover the true <span class="math inline">\(\theta\)</span>, within sampling error of the true coverage of 95%.</p>
<pre class="r"><code>theta=7
alpha1=.025
alpha2=.025
n=100
simul=100

lb &lt;- numeric(simul)
ub &lt;- numeric(simul)
est &lt;- numeric(simul)

set.seed(42070)
for (i in 1:simul) {
  data &lt;- rexp(n) + theta
  t &lt;- min(data)
  est[i] &lt;- t - 1/n
  lb[i] &lt;- t + log(alpha2)/n
  ub[i] &lt;- t + log(1-alpha1)/n
}

library(plotrix)

mycolor &lt;- function(endpoints, mn) {
  if (mn &lt; endpoints[1] | mn &gt; endpoints[2]) 
    &quot;Red&quot; # if confidence interval doesn&#39;t cover true theta
  else 
    &quot;Black&quot; 
}

ci&lt;- cbind(lb, ub)
z &lt;- apply(ci,1,mycolor,theta)

plotCI(x=est, y=1:simul, ui=ub, li=lb, 
       err=&quot;x&quot;, gap=T, col=z, xlab=&quot;Estimate of Theta&quot;, ylab=&quot;Sample Number&quot;)
abline(v=theta)</code></pre>
<p><img src="/2021/08/12/pivoting-a-cdf/index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
</div>
<div id="pareto-family" class="section level2">
<h2>Pareto family</h2>
<p>Let <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> be a random sample from the pdf <span class="math inline">\(f_\theta(x)= \frac{\theta}{x^{\theta+1}}\)</span> for <span class="math inline">\(x &gt; 1\)</span>. This is the Pareto family with unit scale and unknown shape parameter <span class="math inline">\(\theta &gt; 0\)</span>. It’s not too difficult to work out that the cdf of the minimum observation <span class="math inline">\(T=X_{(1)}\)</span> is <span class="math inline">\(F_{\theta}(t)= (1 - t^{-n\theta})\unicode{x1D7D9}(x&gt;1)\)</span>, i.e. the cdf of a Pareto with shape parameter <span class="math inline">\(n\)</span> (and the same unit scale), which is increasing in <span class="math inline">\(\theta\)</span> for every <span class="math inline">\(t\)</span>.</p>
<p>In this case, the equations</p>
<p><span class="math display">\[\begin{align}
\frac{\alpha}{2} &amp;= 1-x^{-n(\theta)} \\       
1-\frac{\alpha}{2} &amp;= 1-x^{-n(\theta)} 
\end{align}\]</span>
each have unique solutions for <span class="math inline">\(\theta\)</span>.</p>
<p>We solve the first to get</p>
<p><span class="math display">\[ L(T)= \frac{-\log \left( 1-\frac{\alpha}{2} \right)}{n\log(T)}
\]</span>
and the second to get
<span class="math display">\[ U(T)= \frac{-\log \left(\frac{\alpha}{2} \right)}{n\log(T)}
\]</span></p>
<pre class="r"><code>library(VGAM)</code></pre>
<pre><code>## Loading required package: stats4</code></pre>
<pre><code>## Loading required package: splines</code></pre>
<pre class="r"><code>theta=3
alpha1=.025
alpha2=.025
n=100
simul=100

lb &lt;- numeric(simul)
ub &lt;- numeric(simul)
est &lt;- numeric(simul)

set.seed(42070)
for (i in 1:simul) {
  data &lt;- rpareto(n, shape=theta)
  est[i] &lt;- 1/mean(log(data)) #mle
  t &lt;- min(data)
  lb[i] &lt;- -log(1-alpha2)/(n*log(t))
  ub[i] &lt;- -log(alpha1)/(n*log(t))
}

library(plotrix)

mycolor &lt;- function(endpoints, mn) {
  if (mn &lt; endpoints[1] | mn &gt; endpoints[2]) 
    &quot;Red&quot; # if confidence interval doesn&#39;t cover true theta
  else 
    &quot;Black&quot; 
}

ci&lt;- cbind(lb, ub)
z &lt;- apply(ci,1,mycolor,theta)

plotCI(x=est, y=1:simul, ui=ub, li=lb, 
       err=&quot;x&quot;, gap=T, col=z, xlab=&quot;Estimate of Theta&quot;, ylab=&quot;Sample Number&quot;, xlim=c(0,10))
abline(v=theta)</code></pre>
<p><img src="/2021/08/12/pivoting-a-cdf/index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>adasds
### Discussion (Notes to the Careful Reader)</p>
<ol style="list-style-type: decimal">
<li><p>The careful reader will observe that although I promised a method that works in all cases, there is a very important condition in the theorem just proved, which is that <span class="math inline">\(F_\theta(t)\)</span> is monotone in <span class="math inline">\(\theta\)</span>. This corresponds to our family of distributions having a monotone likelihood ratio in T, which is a useful condition for finding uniformly most powerful tests using the Karlin Rubin theorem, which is a topic for another blog post. What may come as a surprise is that this condition is not actually needed for us to use the core idea of pivoting a cdf. We can pivot a cdf to get a confidence set even when the condition fails! Instead, the condition is provided in the theorem to ensure that the resulting confidence set is an interval. As we mentioned above, we get a confidence interval when <span class="math inline">\(q(\theta, X)\)</span> is monotone in <span class="math inline">\(\theta\)</span> for every <span class="math inline">\(X\)</span>. Here, our pivot <span class="math inline">\(q(\theta, X)\)</span> is simply <span class="math inline">\(F_\theta(T(X))\)</span>, and so we require it to be monotone in <span class="math inline">\(\theta\)</span> for every <span class="math inline">\(T(X)\)</span>. When we don’t have this condition, we can still invert <span class="math inline">\(\alpha_1 \leq F_\theta(T(X)) \leq 1-\alpha_2\)</span> to get a confidence set for <span class="math inline">\(\theta\)</span>–it just won’t necessarily be an interval.</p></li>
<li><p>The “better” the statistic we start with, the “better” the set estimator
In the most extreme case, suppose we start with an ancillary statistic: a statistic whose distribution is independent of the parameter…</p></li>
</ol>
<p></font></p>
</div>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

